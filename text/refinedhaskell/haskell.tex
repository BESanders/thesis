% \newcommand\rectyp{\FinTy{\tnat}}

\newcommand\factyp{\typ}

\section{Implementation in \toolname}\label{sec:haskell}

We have implemented \declang in \toolname. 
% 
In \S~\ref{sec:termination} we saw real world termination checks.
%
Here claim soundness of \toolname's termination checker, 
as the checker derives as a the transition from \declang to \lhaskell.

\subsection{Termination}

%Let ${\factyp \defeq \tfunbasic{\FinTy{\tnat}}{\FinTy{\tnat}}}$.
Haskell's recursive functions of type ${\tfunbasic{\FinTy{\tnat}}{\typ}}$ 
are represented, in GHC's Core \cite{SulzmannCJD07} as
${\mathtt{let\ rec}\ f = \ \efun{n}{}{e}}$ that is operationally
equivalent to ${\mathtt{let}\ f = \ \etfix{\typ}\ (\efun{n}{}{\efun{f}{}{e}})}$.
Given the type of $\etfix{\typ}$, checking that $f$ has 
type $\tfunbasic{\FinTy{\tnat}}{\typ}$ reduces to checking
$e$ in a \emph{termination-weakened environment} where
$$\tbind{f}{\tfunbasic{\tref{v}{\tnat}{\finite}{v < n}}{\typ}}$$
%
Thus, \toolname proves termination just as \declang 
does: by checking the body in the above environment, 
where the recursive binder is called with $\tnat$ 
inputs that are strictly smaller than $n$.

\mypara{Default Metric}
For example, \toolname proves that 
%
\begin{code}
  fac n = if n == 0 then 1 else n * fac (n-1)
\end{code}
%
has type $\tfunbasic{\FinTy{\tnat}}{\FinTy{\tnat}}$ 
by typechecking the body of @fac@ 
in a termination-weakened environment 
${\mathtt{fac}\ : \tfunbasic{\tref{\ttv}{\tnat}{\finite}{\ttv < \ttn}}{\FinTy{\tnat}}}$.
The recursive call generates the query:
\begin{align*}
\tbind{\ttn}{\{0 \leq \ttn\}}, \lnot (\ttn = 0) \vdash_D &\  \subt{\ttref{v=n-1}}{\ttref{0 \leq v \wedge v < n}}\\ 
%\tlref{n}{\tint}{\finite}{0 \leq n}, \lnot (n = 0) \vdash_D &\  \subt{\ttref{v=n-1}}{\ttref{0 \leq v \wedge v < n}}\\ 
\intertext{Which reduces to the valid VC:}
0 \leq \ttn \wedge \lnot (\ttn = 0) \Rightarrow &\   (\ttv = \ttn-1) \Rightarrow (0 \leq \ttv \wedge \ttv < \ttn)
\end{align*}
%
proving that $\mathtt{fac}$ terminates, in essence because the
\emph{first parameter} forms a \emph{well-founded decreasing metric}.

\mypara{Refinements Enable Termination} 
Consider Euclid's GCD:
%
\begin{code}
  gcd :: a:Nat -> {v:Nat | v < a} -> Nat 
  gcd a 0 = a
  gcd a b = gcd b (a `mod` b)
\end{code}
%
Here, the first parameter is decreasing, but this requires
the fact that the second parameter is smaller than the first 
and that @mod@ returns results smaller than its second 
parameter. Both facts are easily expressed as refinements, 
but elude non-extensible checkers~\cite{Giesl11}.

\mypara{Explicit Termination Metrics}
The indexed-fixpoint combinator technique is easily extended to 
cases where some parameter \emph{other} than the first is the 
well-founded metric. For example, consider: 
% As an example, consider the tail-recursive factorial:
%
\begin{code}
  tfac     :: Nat -> n:Nat -> Nat / [n] 
  tfac x n | n == 0    = x
           | otherwise = tfac (n*x) (n-1)
\end{code}
%
We specify that the \emph{last parameter} is decreasing by 
specifying an explicit termination metric @/ [n]@ in the 
type signature.
%
\toolname \emph{desugars} the 
termination metric into a new $\tnat$-valued \emph{ghost parameter} @d@ 
whose value is always equal to the termination metric @n@:
\begin{code}
  tfac :: d:Nat -> Nat -> {n:Nat | d = n} -> Nat 
  tfac d x n | n == 0    = x
             | otherwise = tfac (n-1) (n*x) (n-1)
\end{code}
%
Type checking, as before, checks the body in an environment where 
the first argument of @tfac@ is weakened, \ie, requires proving @d > n-1@.
%
So, the system needs to know that the ghost argument @d@ 
represents the decreasing metric.
%
We capture this information in the type signature of @tfac@ where the \emph{last} 
argument exactly specifies that @d@ is the termination metric @n@, \ie, @d = n@.
%
Note that since the termination metric can depend on any argument, 
it is important to refine the last argument,
so that all arguments are in scope, with the fact that @d@ is the termination metric.

To generalize, desugaring of termination metrics proceeds as follows.
Let $f$ be a recursive function with parameters $\overline{x}$ and 
termination metric $\mu(\overline{x})$. Then \toolname will
\begin{itemize}
\item add a $\tnat$-valued ghost first parameter $d$ in the definition of $f$, 
\item weaken the last argument of $f$ with the refinement $d = \mu(\overline{x})$, %and
\item at each recursive call of $f\ \overline{e}$, 
apply $\mu(\overline{e})$ as the first argument.
\end{itemize}  
%
%%As will shall see this technique can be used 
%%when the termination metric is any logical expression.

\mypara{Explicit Termination Expressions} 
Let us now apply the previous technique in a function where
none of the parameters themselves decrease across recursive calls,
but there is some \emph{expression} that forms the decreasing metric.
%
%Sometimes, none of the parameters themselves decrease across recursive calls,
%but there is some \emph{expression} that forms the decreasing metric.
%
Consider @range lo hi@ (as in~\S~\ref{sec:termination}), which returns the list of 
@Int@s from @lo@ to @hi@:
%
We generalize the explicit metric specification to 
\emph{expressions} like @hi-lo@. \toolname \emph{desugars} the 
expression into a new $\tnat$-valued \emph{ghost parameter} 
whose value is always equal to @hi-lo@, that is:
\begin{code}
  range :: lo:Nat -> {hi:Nat | hi >= lo} -> [Nat] 
         / [hi-lo]
  range lo hi 
    | lo < hi = lo : range (lo + 1) hi
    | _       = [] 
\end{code}
%
Here, neither parameter is decreasing (indeed, the first one
is \emph{increasing}) but @hi-lo@ decreases across each call. 
%
We generalize the explicit metric specification to 
\emph{expressions} like @hi-lo@. \toolname \emph{desugars} the 
expression into a new $\tnat$-valued \emph{ghost parameter} 
whose value is always equal to @hi-lo@, that is:
%
\begin{code}
  range lo hi = go (hi-lo) lo hi
    where 
      go :: d:Nat -> lo:Nat 
         -> {hi:Nat | d = hi - lo} -> [Nat]
      go d lo hi
       | lo < hi = l : go (hi-(lo+1)) (lo+1) hi 
       | _       = []
\end{code}
%
After which, it proves @go@ terminating, by showing 
that the first argument @d@ is a \tnat that decreases across each 
recursive call (as in @fac@ and @tfac@).

\mypara{Recursion over Data Types}
The above strategy generalizes easily to functions that recurse
over (finite) data structures like arrays, lists, and trees.
In these cases, we simply use \emph{measures} to project the 
structure onto \tnat, thereby reducing the verification to 
the previously seen cases. For each user defined type, \eg
%
\begin{code}
  data L [sz] a = N | C a (L a)
\end{code}
%
we can define a \emph{measure}
%
\begin{code}
  measure sz  :: L a -> Nat
    sz (C x xs) = 1 + (sz xs)
    sz N        = 0
\end{code}
%
We prove that @map@ terminates using the type:
%
\begin{code}
  map :: (a -> b) -> xs:L a -> L b / [sz xs]
  map f (C x xs) = C (f x) (map f xs)
  map f N        = N
\end{code}
%
That is, by simply using @(sz xs)@  as the 
decreasing metric.

\mypara{Generalized Metrics Over Datatypes}
Finally, in many functions there is no single argument 
whose (measure) provably decreases. For example, consider:
%
\begin{code}
  merge :: xs:L a -> ys:L a -> L a / [sz xs + sz ys]
  merge (C x xs) (C y ys)
    | x < y     = x `C` (merge xs  (y `C` ys))
    | otherwise = y `C` (merge (x `C` xs)  ys)
\end{code}
%
from the homonymous sorting routine. Here, neither parameter
decreases, but the \emph{sum} of their sizes does. 
%
As before \toolname desugars the decreasing expression into 
a ghost parameter and thereby proves termination (assuming, 
of course, that the inputs were finite lists, \ie 
$\FinTy{\mathtt{L}}\ a$).

\mypara{Automation: Default Size Measures}
Structural recursion on the first argument is a common pattern 
in \lhaskell code.
%
\toolname automates termination proofs for this common case,
by allowing users to specify a \emph{size measure} 
for each data type, (\eg @sz@ for @L a@).
%
Now, if \emph{no} termination metric is given, by default 
\toolname assumes that the \emph{first} argument whose type
has an associated size measure decreases.
%
Thus, in the above, we need not specify metrics for @fac@ 
or @gcd@ or @map@ as the size measure is automatically 
used to prove termination. 
%
This simple heuristic allows us to {automatically}
prove 67\% of recursive functions terminating.

%%% \mypara{Summary}
%%% To sum up, 
%%% %
%%% \begin{itemize}
%%% \item No termination check for functions marked @lazy@, 
%%% \item If no explicit termination metrice, then first 
%%%       argument with size measure used by default,
%%% \item Otherwise, explicit termination metric desugared 
%%%       into ghost @nat@ parameter that is used to prove 
%%%       termination.
%%% \end{itemize}

\subsection{Non-termination}

By default, \toolname checks that every function is 
terminating. We show in \Sref{sec:refinedhaskell:evaluation} that 
this is in fact the overwhelmingly common case in practice.
%
However, annotating a function as @lazy@ deactivates 
\toolname's termination check (and marks the result as a 
\Div type).
%
This allows us to check functions that are 
non-terminating, and allows \toolname to prove safety 
properties of programs that manipulate \emph{infinite} 
data, such as streams, which arise idiomatically with 
Haskell's lazy semantics.
% 
For example, consider the classic @repeat@ function:
%
\begin{code}
  repeat x = x `C` repeat x
\end{code}
%
We cannot use the $\etfix{}$ combinators to 
represent this kind of recursion, and hence, 
use the non-terminating $\efix{}$ combinator 
instead. 
%
I \toolname, we use the @lazy@ keyword to denote 
potentially diverging definitions 
defined using the non-terminating $\efix{}$ combinator.


\begin{comment}
Abstract Streams

Let us see how we can use refinements to statically 
distinguish between finite and infinite streams. 
The direct, \emph{global} route of using a measure
%
\begin{code}
  measure inf    :: L a -> Prop 
    inf (C x xs) = inf xs
    inf N        = false 
\end{code}
%
to describe infinite lists is unavailable as such 
a measure, and hence, the corresponding refinement
would be non-terminating.
%
Instead, we describe infinite lists in \emph{local} 
fashion, by stating that each \emph{tail} is non-empty.

\mypara{Step 1: Abstract Refinements} 
We can parametrize a datatype with abstract 
refinements that relate sub-parts of the 
structure \cite{vazou13}. 
For example, we parameterize the list type as:
%
\begin{code}
  data L a <p :: L a -> Prop> 
    = N | C a {v: L<p> a | (p v)}
\end{code}
%
which parameterizes the list with a refinement 
@p@ which holds \emph{for each} tail of the list, 
\ie holds for each of the second arguments to 
the @C@ constructor in each sub-list.


\mypara{Step 2: Measuring Emptiness} Now, we can write a measure that 
states when a list is \emph{empty}
%
\begin{code}
  measure emp  :: L a -> Prop 
    emp N        = true
    emp (C x xs) = false
\end{code}
%
As described in \Sref{sec:typing}, \toolname translates the 
abstract refinements and measures into refined types for 
@N@ and @C@.

\mypara{Step 3: Specification \& Verification}
Finally, we can use the abstract refinements and measures to 
write a type alias describing a refined version of @L a@ 
representing infinite streams:
%
\begin{code}
  type Stream a = 
    {xs: L <{\v -> not(emp v)}> a | not(emp xs)}
\end{code}
%
We can now type @repeat@ as:
%
\begin{code}
  lazy repeat :: a -> Stream a
  repeat x    = x `C` repeat x 
\end{code}
%
The @lazy@ keyword \emph{deactivates} termination checking, and 
marks the output as a \Div type.
%
Even more interestingly, we can prove safety properties of 
infinite lists, for example:
%
\begin{code}
  take            :: Nat -> Stream a -> L a
  take 0 _        = N
  take n (C x xs) = x `C` take (n-1) xs
  take _ N        = error "never happens"
\end{code}
%
\toolname proves, similar to the @head@ example from
\Sref{sec:overview}, that we never match a @N@ when 
the input is a @Stream@.

\mypara{Finite vs. Infinite Lists}
%
Thus, the combination of refinements 
and labels allows our stratified type 
system to specify and verify whether 
a list is finite or infinite.
%
Note that:
%
$\FinTy{\mathtt{L}}\ a$ represents
\emph{finite} lists \ie those 
produced using the (inductive) 
terminating fixpoint combinators,
%
$\WnfTy{\mathtt{L}}\ a$ represents 
(potentially) infinite lists which 
are guaranteed to reduce to values, 
\ie non-diverging computations that
yield finite or infinite lists,
and
$\DivTy{\mathtt{L}}\ a$ represents 
computations that may diverge or 
produce a finite or infinite list.

\end{comment}

\subsection{User Specifications and Type Inference}

In program verification it is common that the user provides functional
specification that the code should satisfy.
In \toolname these specifications can be provided as type signatures 
for @let@-bound variables.
%
Consider the typechecking rules of Figure~\ref{fig:typing}
that is used by \declang.
%
$$
\inference{
	\hastype{\Gamma}{e_x}{\tau_{x}} &&
	\hastype{\Gamma,\tbind{x}{\tau_x}}{e}{\tau} &&
	\iswellformed{\Gamma}{\tau}
}{
	\hastype{\Gamma}{\elet{x}{e_x}{e}}{\tau}
}[\rtlet]
$$
%
Note that \rtlet \emph{guesses} an appropriate type $\tau_x$
for $e_x$ and binds it to $x$ to typecheck $e$.

\toolname allows the user to specify the type $\tau_x$ for top level bindings.
%
For every binding \elet{x}{e_x}{\dots}, if the user provides a type specification $\tau_x$,
\toolname checks using the appropriate environment 
(1)~that the specified type is well-formed and 
(2)~that the expression $e_x$ typechecks under the specification $\tau_x$.
%
For the other top level bindings, \ie those without user-provided specifications, 
as well as all local bindings, \toolname uses the Liquid Types~\citep{LiquidPLDI08} 
framework to infer refinement types, thus greatly reducing the number of annotations 
required from the user.


